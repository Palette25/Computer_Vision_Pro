{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000, 1, 28, 28])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:55: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "E:\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:45: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "E:\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:60: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "E:\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:50: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# torch.manual_seed(1)\n",
    "\n",
    "# Enlarge EPOCH to 5, and set lower learning rate\n",
    "EPOCH = 10\n",
    "LR = 0.0001\n",
    "DOWNLOAD_MNIST = False\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(root='./mnist/', train=True, transform=torchvision.transforms.ToTensor(),\n",
    "                                        download=DOWNLOAD_MNIST)\n",
    "test_data = torchvision.datasets.MNIST(root='./mnist/', train=False)\n",
    "print(train_data.train_data.shape)\n",
    "\n",
    "train_x = torch.unsqueeze(train_data.train_data, dim=1).type(torch.FloatTensor) / 255.\n",
    "train_y = train_data.train_labels\n",
    "print(train_x.shape)\n",
    "\n",
    "test_x = torch.unsqueeze(test_data.test_data, dim=1).type(torch.FloatTensor)[:10000] / 255.  # Tensor on GPU\n",
    "test_y = test_data.test_labels[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1, 28, 28])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20221b37250>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_x[0,0,:,:].numpy(), 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义神经网络类Net\n",
    "#### 1. 实现卷积层与全连接层代码\n",
    "#### 2. 增加dropout与BN技巧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Two Layer CNN\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        # Two Layer Full-Connected Network\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "        # Batch Normalization Layers\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
    "        # Drop Out Layer\n",
    "        self.dropout = nn.Dropout(p=0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = F.relu(self.conv1(x))\n",
    "        x2 = F.max_pool2d(x1, (2,2)) # Max Pooling with pooling kernel size 2X2\n",
    "        x2 = self.batchnorm1(x2)     # Batch Normalization with switch\n",
    "        x3 = F.relu(self.conv2(x2))  \n",
    "        x4 = F.max_pool2d(x3, (2,2)) # Max Pooling with pooling kernel size 2X2\n",
    "        x4 = self.batchnorm2(x4)     # Batch Normalization with switch\n",
    "        x5 = x4.view(x4.size(0), -1)\n",
    "        x5 = self.dropout(x5)        # Add Dropout with switch\n",
    "        x6 = F.relu(self.fc1(x5))\n",
    "        output = F.log_softmax(self.fc2(x6), dim=1)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=1568, out_features=500, bias=True)\n",
      "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
      "  (batchnorm1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      ")\n",
      "torch.Size([16, 1, 3, 3])\n",
      "torch.Size([16])\n",
      "torch.Size([32, 16, 3, 3])\n",
      "torch.Size([32])\n",
      "torch.Size([500, 1568])\n",
      "torch.Size([500])\n",
      "torch.Size([10, 500])\n",
      "torch.Size([10])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "Epoch:  0 | train loss: 2.3406 | test accuracy: 0.1445\n",
      "Epoch:  0 | train loss: 0.3031 | test accuracy: 0.9443\n",
      "Epoch:  0 | train loss: 0.1408 | test accuracy: 0.9621\n",
      "Epoch:  0 | train loss: 0.0821 | test accuracy: 0.9704\n",
      "Epoch:  0 | train loss: 0.1142 | test accuracy: 0.9744\n",
      "Epoch:  0 | train loss: 0.1060 | test accuracy: 0.9799\n",
      "Epoch:  1 | train loss: 0.0579 | test accuracy: 0.9804\n",
      "Epoch:  1 | train loss: 0.1074 | test accuracy: 0.9823\n",
      "Epoch:  1 | train loss: 0.0327 | test accuracy: 0.9839\n",
      "Epoch:  1 | train loss: 0.0939 | test accuracy: 0.9836\n",
      "Epoch:  1 | train loss: 0.0405 | test accuracy: 0.9841\n",
      "Epoch:  1 | train loss: 0.0312 | test accuracy: 0.9859\n",
      "Epoch:  2 | train loss: 0.0970 | test accuracy: 0.9869\n",
      "Epoch:  2 | train loss: 0.0290 | test accuracy: 0.9871\n",
      "Epoch:  2 | train loss: 0.0247 | test accuracy: 0.9863\n",
      "Epoch:  2 | train loss: 0.0329 | test accuracy: 0.9873\n",
      "Epoch:  2 | train loss: 0.0307 | test accuracy: 0.9881\n",
      "Epoch:  2 | train loss: 0.0058 | test accuracy: 0.9875\n",
      "Epoch:  3 | train loss: 0.0150 | test accuracy: 0.9878\n",
      "Epoch:  3 | train loss: 0.0190 | test accuracy: 0.9873\n",
      "Epoch:  3 | train loss: 0.0200 | test accuracy: 0.9881\n",
      "Epoch:  3 | train loss: 0.0185 | test accuracy: 0.9878\n",
      "Epoch:  3 | train loss: 0.0093 | test accuracy: 0.9883\n",
      "Epoch:  3 | train loss: 0.0174 | test accuracy: 0.9876\n",
      "Epoch:  4 | train loss: 0.0158 | test accuracy: 0.9881\n",
      "Epoch:  4 | train loss: 0.0206 | test accuracy: 0.9893\n",
      "Epoch:  4 | train loss: 0.0165 | test accuracy: 0.9889\n",
      "Epoch:  4 | train loss: 0.0065 | test accuracy: 0.9893\n",
      "Epoch:  4 | train loss: 0.0212 | test accuracy: 0.9882\n",
      "Epoch:  4 | train loss: 0.0382 | test accuracy: 0.9895\n",
      "Epoch:  5 | train loss: 0.0074 | test accuracy: 0.9895\n",
      "Epoch:  5 | train loss: 0.0063 | test accuracy: 0.9894\n",
      "Epoch:  5 | train loss: 0.0179 | test accuracy: 0.9887\n",
      "Epoch:  5 | train loss: 0.0416 | test accuracy: 0.9898\n",
      "Epoch:  5 | train loss: 0.0169 | test accuracy: 0.9898\n",
      "Epoch:  5 | train loss: 0.0115 | test accuracy: 0.9893\n",
      "Epoch:  6 | train loss: 0.0111 | test accuracy: 0.9883\n",
      "Epoch:  6 | train loss: 0.0160 | test accuracy: 0.9903\n",
      "Epoch:  6 | train loss: 0.0019 | test accuracy: 0.9886\n",
      "Epoch:  6 | train loss: 0.0075 | test accuracy: 0.9899\n",
      "Epoch:  6 | train loss: 0.0081 | test accuracy: 0.9894\n",
      "Epoch:  6 | train loss: 0.0173 | test accuracy: 0.9897\n",
      "Epoch:  7 | train loss: 0.0039 | test accuracy: 0.9897\n",
      "Epoch:  7 | train loss: 0.0052 | test accuracy: 0.9896\n",
      "Epoch:  7 | train loss: 0.0179 | test accuracy: 0.9893\n",
      "Epoch:  7 | train loss: 0.0022 | test accuracy: 0.9892\n",
      "Epoch:  7 | train loss: 0.0037 | test accuracy: 0.9899\n",
      "Epoch:  7 | train loss: 0.0006 | test accuracy: 0.9895\n",
      "Epoch:  8 | train loss: 0.0044 | test accuracy: 0.9904\n",
      "Epoch:  8 | train loss: 0.0061 | test accuracy: 0.9894\n",
      "Epoch:  8 | train loss: 0.0012 | test accuracy: 0.9900\n",
      "Epoch:  8 | train loss: 0.0013 | test accuracy: 0.9900\n",
      "Epoch:  8 | train loss: 0.0083 | test accuracy: 0.9898\n",
      "Epoch:  8 | train loss: 0.0032 | test accuracy: 0.9896\n",
      "Epoch:  9 | train loss: 0.0019 | test accuracy: 0.9899\n",
      "Epoch:  9 | train loss: 0.0030 | test accuracy: 0.9903\n",
      "Epoch:  9 | train loss: 0.0048 | test accuracy: 0.9904\n",
      "Epoch:  9 | train loss: 0.0032 | test accuracy: 0.9887\n",
      "Epoch:  9 | train loss: 0.0037 | test accuracy: 0.9885\n",
      "Epoch:  9 | train loss: 0.0114 | test accuracy: 0.9895\n",
      "tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9], device='cuda:0') prediction number\n",
      "tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9]) real number\n",
      "Max Accuracy: 0.9904\n"
     ]
    }
   ],
   "source": [
    "# Use multimodels for ensambling\n",
    "net = Net()\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "net.to(device)\n",
    "\n",
    "print(net)\n",
    "for parameters in net.parameters():\n",
    "    print(parameters.size())\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=LR)\n",
    "\n",
    "# loss_func = nn.MSELoss()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# Enlarge dataSize and BatchSize\n",
    "data_size = 60000\n",
    "batch_size = 50\n",
    "\n",
    "max_accuracy = 0\n",
    "best_params = []\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    random_indx = np.random.permutation(data_size)\n",
    "    for batch_i in range(data_size // batch_size):\n",
    "        indx = random_indx[batch_i * batch_size:(batch_i + 1) * batch_size]\n",
    "\n",
    "        b_x = train_x[indx, :].to(device)\n",
    "        b_y = train_y[indx].to(device)\n",
    "\n",
    "        output = net(b_x)\n",
    "            \n",
    "        loss = loss_func(output, b_y)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch_i % 50 == 0:\n",
    "            test_output = net(test_x.to(device))\n",
    "            \n",
    "            # Use voting mechanism to deicide final predicted label\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            accuracy = torch.sum(pred_y == test_y.to(device)).type(torch.FloatTensor) / test_y.size(0)\n",
    "            \n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.cpu().numpy(), '| test accuracy: %.4f' % accuracy)\n",
    "            if(accuracy > max_accuracy): \n",
    "                max_accuracy = accuracy\n",
    "                torch.save(net, 'best_net.pkl')\n",
    "\n",
    "test_output = net(test_x[:10].to(device))\n",
    "pred_y = torch.max(test_output, 1)[1].data.squeeze()  # move the computation in GPU\n",
    "\n",
    "print(pred_y, 'prediction number')\n",
    "print(test_y[:10], 'real number')\n",
    "print('Max Accuracy: %.4f' % max_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4] prediction number\n",
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4] real number\n"
     ]
    }
   ],
   "source": [
    "net = torch.load('best_net.pkl')\n",
    "\n",
    "test_output = net(test_x[:20].to(device))\n",
    "pred_y = torch.max(test_output, 1)[1].data.squeeze()  # move the computation in GPU\n",
    "\n",
    "print(pred_y.cpu().numpy(), 'prediction number')\n",
    "print(test_y[:20].cpu().numpy(), 'real number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x[:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6dd5d4b8985b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(test_x[:1].numpy().squeeze(), 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import num"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
